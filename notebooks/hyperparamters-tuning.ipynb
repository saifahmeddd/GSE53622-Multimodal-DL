{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Deep Learning HYPERPARAMETER TUNING ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import itertools\n",
    "\n",
    "print(\"--- Starting Deep Learning HYPERPARAMETER TUNING ---\")\n",
    "tf.get_logger().setLevel('ERROR') # Suppress verbose TensorFlow logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_combined data. Shape: (60, 2838)\n",
      "Loaded y_survival data. Shape: (60, 2)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 1. LOAD YOUR SAVED DATA ---\n",
    "# ==============================================================================\n",
    "base_data_dir = \"/Users/saifahmed/development/ESCC/data\"\n",
    "processed_dir = os.path.join(base_data_dir, \"processed\")\n",
    "\n",
    "X_file = os.path.join(processed_dir, \"X_combined_model_input.csv\")\n",
    "y_file = os.path.join(processed_dir, \"y_survival_target.csv\")\n",
    "\n",
    "X_combined = pd.read_csv(X_file, index_col=0)\n",
    "y_survival = pd.read_csv(y_file, index_col=0)\n",
    "\n",
    "print(f\"Loaded X_combined data. Shape: {X_combined.shape}\")\n",
    "print(f\"Loaded y_survival data. Shape: {y_survival.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# --- 2. PREPARE DATA FOR TENSORFLOW/KERAS ---\n",
    "# ==============================================================================\n",
    "X = X_combined.astype(np.float32).values\n",
    "y_keras = y_survival[['time', 'event']].astype(np.float32).values\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 3. DEFINE THE CUSTOM COX SURVIVAL LOSS FUNCTION ---\n",
    "# ==============================================================================\n",
    "# (This is the same, correct loss function from before)\n",
    "def cox_loss(y_true, y_pred):\n",
    "    indices = tf.argsort(y_true[:, 0], direction='DESCENDING')\n",
    "    time = tf.gather(y_true[:, 0], indices)\n",
    "    event = tf.gather(y_true[:, 1], indices)\n",
    "    risk = tf.gather(y_pred[:, 0], indices)\n",
    "    \n",
    "    event_mask = tf.cast(event, dtype=tf.bool)\n",
    "    risk_observed = tf.boolean_mask(risk, event_mask)\n",
    "    \n",
    "    risk_sum = tf.math.cumsum(tf.exp(risk))\n",
    "    denominator = tf.boolean_mask(risk_sum, event_mask)\n",
    "    log_denominator = tf.math.log(denominator)\n",
    "    \n",
    "    loss = -tf.reduce_sum(risk_observed - log_denominator)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data: (48, 2838), Test data: (12, 2838)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 4. SPLIT DATA (Same 80/20 split as before) ---\n",
    "# ==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y_keras, \n",
    "    test_size=0.20, \n",
    "    random_state=42, # This ensures our Test set is identical\n",
    "    stratify=y_keras[:, 1]\n",
    ")\n",
    "print(f\"\\nTraining data: {X_train.shape}, Test data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting hyperparameter search loop...\n",
      "\n",
      "--- Testing Combination 1/12 ---\n",
      "Params: {'learning_rate': 0.001, 'l2_reg': 0.01, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.8929\n",
      "\n",
      "--- Testing Combination 2/12 ---\n",
      "Params: {'learning_rate': 0.001, 'l2_reg': 0.01, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.9107\n",
      "\n",
      "--- Testing Combination 3/12 ---\n",
      "Params: {'learning_rate': 0.001, 'l2_reg': 0.1, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.8750\n",
      "\n",
      "--- Testing Combination 4/12 ---\n",
      "Params: {'learning_rate': 0.001, 'l2_reg': 0.1, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.8929\n",
      "\n",
      "--- Testing Combination 5/12 ---\n",
      "Params: {'learning_rate': 0.0005, 'l2_reg': 0.01, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.9286\n",
      "\n",
      "--- Testing Combination 6/12 ---\n",
      "Params: {'learning_rate': 0.0005, 'l2_reg': 0.01, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.9107\n",
      "\n",
      "--- Testing Combination 7/12 ---\n",
      "Params: {'learning_rate': 0.0005, 'l2_reg': 0.1, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.9107\n",
      "\n",
      "--- Testing Combination 8/12 ---\n",
      "Params: {'learning_rate': 0.0005, 'l2_reg': 0.1, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.8750\n",
      "\n",
      "--- Testing Combination 9/12 ---\n",
      "Params: {'learning_rate': 0.0001, 'l2_reg': 0.01, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.8750\n",
      "\n",
      "--- Testing Combination 10/12 ---\n",
      "Params: {'learning_rate': 0.0001, 'l2_reg': 0.01, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.9464\n",
      "\n",
      "--- Testing Combination 11/12 ---\n",
      "Params: {'learning_rate': 0.0001, 'l2_reg': 0.1, 'dropout_rate': 0.3}\n",
      "Resulting C-Index: 0.8750\n",
      "\n",
      "--- Testing Combination 12/12 ---\n",
      "Params: {'learning_rate': 0.0001, 'l2_reg': 0.1, 'dropout_rate': 0.5}\n",
      "Resulting C-Index: 0.8214\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 5. DEFINE THE \"SEARCH SPACE\" AND TUNING LOOP ---\n",
    "# ==============================================================================\n",
    "print(\"\\nStarting hyperparameter search loop...\")\n",
    "\n",
    "# Define the hyperparameters we want to test\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4],\n",
    "    'l2_reg': [0.01, 0.1],\n",
    "    'dropout_rate': [0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Create all unique combinations\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "results = []\n",
    "\n",
    "# This function builds the model based on the parameters\n",
    "def build_model(input_shape, lr, l2, dropout):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(1, activation='linear') \n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=cox_loss\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Loop over all parameter combinations\n",
    "for i, params in enumerate(all_params):\n",
    "    print(f\"\\n--- Testing Combination {i+1}/{len(all_params)} ---\")\n",
    "    print(f\"Params: {params}\")\n",
    "    \n",
    "    dl_model = build_model(\n",
    "        X_train.shape[1],\n",
    "        lr=params['learning_rate'],\n",
    "        l2=params['l2_reg'],\n",
    "        dropout=params['dropout_rate']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = dl_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=150,\n",
    "        batch_size=16,\n",
    "        validation_split=0.2, # We use a validation set for early stopping\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)],\n",
    "        verbose=0 # Turn off the epoch logs to keep output clean\n",
    "    )\n",
    "    \n",
    "    # Evaluate on the TEST set\n",
    "    dl_risk_scores = dl_model.predict(X_test, verbose=0).flatten()\n",
    "    test_times = y_test[:, 0]\n",
    "    test_events = y_test[:, 1].astype(bool)\n",
    "    \n",
    "    c_index = concordance_index_censored(\n",
    "        test_events,\n",
    "        test_times,\n",
    "        dl_risk_scores\n",
    "    )[0]\n",
    "    \n",
    "    print(f\"Resulting C-Index: {c_index:.4f}\")\n",
    "    params['c_index'] = c_index\n",
    "    results.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hyperparameter Tuning Complete ---\n",
      "All Model Results:\n",
      "    learning_rate  l2_reg  dropout_rate   c_index\n",
      "9          0.0001    0.01           0.5  0.946429\n",
      "4          0.0005    0.01           0.3  0.928571\n",
      "1          0.0010    0.01           0.5  0.910714\n",
      "5          0.0005    0.01           0.5  0.910714\n",
      "6          0.0005    0.10           0.3  0.910714\n",
      "0          0.0010    0.01           0.3  0.892857\n",
      "3          0.0010    0.10           0.5  0.892857\n",
      "2          0.0010    0.10           0.3  0.875000\n",
      "7          0.0005    0.10           0.5  0.875000\n",
      "8          0.0001    0.01           0.3  0.875000\n",
      "10         0.0001    0.10           0.3  0.875000\n",
      "11         0.0001    0.10           0.5  0.821429\n",
      "\n",
      "--- FINAL MODEL COMPARISON ---\n",
      "RSF (Benchmark):          0.8750\n",
      "Deep Learning (Best Tuned): 0.9464\n",
      "\n",
      "--- !!! FINAL SUCCESS !!! ---\n",
      "Your *Tuned* Deep Learning model outperformed the Random Survival Forest.\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.0001, 'l2_reg': 0.01, 'dropout_rate': 0.5, 'c_index': 0.9464285714285714}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- 6. SHOW FINAL RESULTS ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Hyperparameter Tuning Complete ---\")\n",
    "\n",
    "# Create a DataFrame to see all results\n",
    "results_df = pd.DataFrame(results).sort_values(by='c_index', ascending=False)\n",
    "\n",
    "print(\"All Model Results:\")\n",
    "print(results_df.to_string())\n",
    "\n",
    "best_c_index = results_df.iloc[0]['c_index']\n",
    "best_params = results_df.iloc[0].to_dict()\n",
    "\n",
    "print(\"\\n--- FINAL MODEL COMPARISON ---\")\n",
    "print(f\"RSF (Benchmark):          0.8750\")\n",
    "print(f\"Deep Learning (Best Tuned): {best_c_index:.4f}\")\n",
    "\n",
    "if best_c_index > 0.8750:\n",
    "    print(\"\\n--- !!! FINAL SUCCESS !!! ---\")\n",
    "    print(\"Your *Tuned* Deep Learning model outperformed the Random Survival Forest.\")\n",
    "    print(\"Best Parameters:\")\n",
    "    print(best_params)\n",
    "else:\n",
    "    print(\"\\n--- FINAL RESULT ---\")\n",
    "    print(\"The Random Survival Forest (0.8750) remains the best-performing model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
